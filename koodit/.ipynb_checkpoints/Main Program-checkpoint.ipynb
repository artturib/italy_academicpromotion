{
 "metadata": {
  "name": "",
  "signature": "sha256:043187d39499a14ba0648a65867e9a1a1323659cb5cd474607ff54e13357e0b1"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#imports\n",
      "import pandas as pd\n",
      "import gensim\n",
      "import os\n",
      "import pickle\n",
      "import numpy as np\n",
      "import Stemmer\n",
      "from nltk.stem.snowball import SnowballStemmer\n",
      "import string\n",
      "import nltk\n",
      "import codecs\n",
      "import subprocess\n",
      "import tempfile"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Parameters\n",
      "class Params:\n",
      "    defaultdirectory = {'uni':'C:\\Users\\k92352\\Google Drive\\projektit\\paperit\\italy_academicpromotion\\koodit',\n",
      "                        'koti': 'C:\\Users\\Artturi\\Google Drive\\projektit\\paperit\\italy_academicpromotion\\koodit'}\n",
      "                  \n",
      "    datadirectory = {'koti' : 'C:/Users/Artturi/Google Drive/projektit/paperit/italy_academicpromotion/data/',\n",
      "                     'uni' : 'C:/Users/k92352/Google Drive/projektit/paperit/italy_academicpromotion/data/'}\n",
      "    \n",
      "    rawdatadirectory = {'koti' : 'C:/Users/Artturi/datat/manuel/',\n",
      "                        'uni' : 'Y:/artturi/manuel_data/'}\n",
      "    \n",
      "    mallet_path = {'koti' : 'C:/Program Files (x86)/Mallet/bin/mallet',\n",
      "                        'uni' : 'C:/Users/k92352/mallet'}\n",
      "                   \n",
      "    samplesize = 1000\n",
      "    testsetsize = 10 #percentage of observations used for testing\n",
      "    evaluatorwordfilter = 0.8\n",
      "\n",
      "    if os.getcwd() == defaultdirectory['koti']:\n",
      "        datadirectory = datadirectory['koti']\n",
      "        defaultdirectory = defaultdirectory['koti']\n",
      "        rawdatadirectory = rawdatadirectory['koti']\n",
      "        mallet_path = mallet_path['koti']\n",
      "    else:\n",
      "        datadirectory = datadirectory['uni']\n",
      "        defaultdirectory = defaultdirectory['uni']\n",
      "        rawdatadirectory = rawdatadirectory['uni']\n",
      "        mallet_path = mallet_path['uni']\n",
      "    stemmer = Stemmer.Stemmer('italian')\n",
      "    stopwords = nltk.corpus.stopwords.words('italian')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# reading the csv\n",
      "data = pd.read_csv(Params.rawdatadirectory+'data2.csv',delimiter='\\t')\n",
      "\n",
      "italians = data[data.italian_evaluator==1]\n",
      "print len(italians)\n",
      "italians = italians.dropna(axis=0,inplace=False,subset=['evaluation'])\n",
      "print len(italians)\n",
      "italians = italians.set_index(['candidate_number','evaluator_number']).sort()\n",
      "italians.drop('id',inplace=True,axis='columns')\n",
      "\n",
      "italians.to_pickle(Params.rawdatadirectory+'italians.pkl')\n",
      "\n",
      "italian_evaluations = italians.evaluation\n",
      "italian_evaluations.to_pickle(Params.rawdatadirectory+'italian_evaluations.pkl')\n",
      "\n",
      "italian_metadata = italians.drop(['evaluation','collegiale'],inplace=False,axis='columns')\n",
      "#italian_metadata = italian_metadata.set_index(['candidate_number','evaluator_number']).sort()\n",
      "\n",
      "gender = pd.read_table(Params.rawdatadirectory+'candidates_gender.txt',index_col=0)\n",
      "firsts = italian_metadata.index.get_level_values('candidate_number')\n",
      "italian_metadata['female'] = gender.ix[firsts].values\n",
      "italian_metadata.to_pickle(Params.rawdatadirectory+'italian_metadata.pkl')\n",
      "\n",
      "italian_tokens = pd.Series([Params.stemmer.stemWords([token for token in nltk.word_tokenize(evaluation.lower()) \n",
      "                                         if token not in Params.stopwords and not token.isdigit() and len(token)>2])\n",
      "               for evaluation in italian_evaluations],index=italian_evaluations.index)\n",
      "italian_tokens.to_pickle(Params.rawdatadirectory+'italian_tokens.pkl')\n",
      "\n",
      "italian_evaluator_pruned_tokens = pd.Series(index=italian_tokens.index)\n",
      "for evaluator in italian_metadata.fullname_evaluator.unique():\n",
      "    idx = italian_metadata.fullname_evaluator == evaluator\n",
      "    tokenized_texts = italian_tokens[idx].tolist()\n",
      "    tempdictionary = gensim.corpora.Dictionary(tokenized_texts)\n",
      "    tempdictionary.filter_extremes(no_above=Params.evaluatorwordfilter)\n",
      "    italian_evaluator_pruned_tokens.loc[idx] = [[token for token in text if token in set(tempdictionary.token2id.keys())] for text in tokenized_texts]\n",
      "\n",
      "italian_evaluator_pruned_tokens.to_pickle(Params.rawdatadirectory+'italian_evaluator_pruned_tokens.pkl')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# loads\n",
      "italians = pd.read_pickle(Params.rawdatadirectory+'italians.pkl')\n",
      "#italian_evaluations = pd.read_pickle(Params.rawdatadirectory+'italian_evaluations.pkl')\n",
      "#italian_metadata = pd.read_pickle(Params.rawdatadirectory+'italian_metadata.pkl')\n",
      "#italian_evaluator_pruned_tokens = pd.read_pickle(Params.rawdatadirectory+'italian_evaluator_pruned_tokens.pkl')\n",
      "#italian_tokens = pd.read_pickle(Params.rawdatadirectory+'italian_tokens.pkl')\n",
      "\n",
      "#dictionary = gensim.corpora.Dictionary.load(Params.rawdatadirectory+'italians.dict')\n",
      "#corpus = gensim.corpora.MmCorpus(Params.rawdatadirectory+'italians.corp')\n",
      "#model = gensim.models.ldamodel.LdaModel.load(Params.rawdatadirectory+'italians.lda')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 40
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# saves\n",
      "#dictionary.save('../data/italians.dict')\n",
      "gensim.corpora.MmCorpus.serialize('../data/italians.corp', corpus)\n",
      "italian_metadata.to_pickle(Params.rawdatadirectory+'italian_metadata.pkl')\n",
      "#model.save(Params.rawdatadirectory+'italians_mallet.lda')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "AttributeError",
       "evalue": "'list' object has no attribute 'save'",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-16-41c6d2ae9b7d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# saves\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../data/italians.dict'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mcorpus\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../data/italians.corp'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;31m#mallet_lda.save(Params.rawdatadirectory+'italians_mallet.lda')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'save'"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# finding the candidates for whiche the evaluations are indentical\n",
      "same_evaluations = set()\n",
      "for applicant in italian_evaluator_pruned_tokens.index.get_level_values('candidate_number'):\n",
      "    x = italian_evaluator_pruned_tokens.ix[applicant].tolist()\n",
      "    if x.count(x[0]) == len(x):\n",
      "        same_evaluations.update([applicant])\n",
      "same_evaluations = sorted(list(same_evaluations))\n",
      "\n",
      "f1 = open('../output/same_evaluation.txt','w')\n",
      "print >> f1, sorted(list(same_evaluations))\n",
      "f1.close()\n",
      "\n",
      "print len(same_evaluations)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "1721\n"
       ]
      }
     ],
     "prompt_number": 41
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "Params.mallet_path"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 26,
       "text": [
        "'C:/Users/k92352/mallet/bin/mallet'"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# build features\n",
      "\n",
      "italian_metadata['female_in_committee'] = italian_metadata.female_evaluator.groupby('candidate_number').sum()>0.values\n",
      "\n",
      "italian_metadata['female*female_in_committee'] = italian_metadata.loc[:,'female_in_committee']*italian_metadata.loc[:,'female']\n",
      "\n",
      "italian_metadata['female*female_evaluator'] = italian_metadata.loc[:,'female*female_in_committee']*italian_metadata.loc[:,'female_evaluator']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# using MALLET\n",
      "import DMRmallet\n",
      "\n",
      "DMRmallet.DMRMallet(Params.mallet_path,corpus=corpus,covariates=covariates,num_topics=10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "TypeError",
       "evalue": "__init__() takes at least 2 arguments (1 given)",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-23-08b8394b1a4f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDMRmallet\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mDMRmallet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDMRMallet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[1;31mTypeError\u001b[0m: __init__() takes at least 2 arguments (1 given)"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dictionary1 = gensim.corpora.Dictionary(tokens.tolist())\n",
      "dictionary1.filter_extremes(no_below=5, no_above=0.25)\n",
      "corpus1 = [dictionary1.doc2bow(evaluation) for evaluation in tokens.tolist()]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# fit a LDA with mallet\n",
      "mallet_lda = gensim.models.LdaMallet(Params.mallet_path, corpus, id2word=dictionary, num_topics=100)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# fit gensim LDA\n",
      "gensim_lda = gensim.models.LdaModel(corpus, id2word=dictionary, num_topics=100,passes=10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# making the texts into mallet compatible\n",
      "\n",
      "TEXTS_FILE = Params.rawdatadirectory+'texts.txt'\n",
      "\n",
      "with codecs.open(TEXTS_FILE, 'w', encoding='utf-8') as texts_file:\n",
      "    for token in tokens:\n",
      "        text = u' '.join([x for x in token])\n",
      "        texts_file.write(text + u'\\n')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "TEXTS_FILE = Params.rawdatadirectory+'texts.txt'\n",
      "TEXTS_FILE"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 4,
       "text": [
        "'Y:/artturi/manuel_data/texts.txt'"
       ]
      }
     ],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# making the features into mallet compatible\n",
      "\n",
      "FEATURES_FILE = Params.rawdatadirectory+'features.txt'\n",
      "italian_metadata.loc[:,['field','promoted']].to_csv(FEATURES_FILE, sep=' ',index=False,header=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 40
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "path = Params.mallet_path\n",
      "subprocess.call(import_args)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "MALLET = [Params.mallet_path, \"run\"]\n",
      "INSTANCES_FILE = \"instances.mallet\"\n",
      "TOPICS = 50\n",
      "\n",
      "import_args = MALLET + [\"cc.mallet.topics.tui.DMRLoader\", TEXTS_FILE, FEATURES_FILE, INSTANCES_FILE]\n",
      "import_return = subprocess.call(import_args)\n",
      "\n",
      "process_args = MALLET + [\"cc.mallet.topics.DMRTopicModel\", INSTANCES_FILE, str(TOPICS)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "WindowsError",
       "evalue": "[Error 193] %1 is not a valid Win32 application",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[1;31mWindowsError\u001b[0m                              Traceback (most recent call last)",
        "\u001b[1;32m<ipython-input-42-568bb80855a6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mimport_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMALLET\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"cc.mallet.topics.tui.DMRLoader\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTEXTS_FILE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFEATURES_FILE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mINSTANCES_FILE\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mimport_return\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msubprocess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimport_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mprocess_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMALLET\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"cc.mallet.topics.DMRTopicModel\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mINSTANCES_FILE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTOPICS\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mC:\\Anaconda\\lib\\subprocess.pyc\u001b[0m in \u001b[0;36mcall\u001b[1;34m(*popenargs, **kwargs)\u001b[0m\n\u001b[0;32m    520\u001b[0m     \u001b[0mretcode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"ls\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"-l\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    521\u001b[0m     \"\"\"\n\u001b[1;32m--> 522\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mPopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mpopenargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    523\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    524\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mC:\\Anaconda\\lib\\subprocess.pyc\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags)\u001b[0m\n\u001b[0;32m    708\u001b[0m                                 \u001b[0mp2cread\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp2cwrite\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    709\u001b[0m                                 \u001b[0mc2pread\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc2pwrite\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 710\u001b[1;33m                                 errread, errwrite)\n\u001b[0m\u001b[0;32m    711\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    712\u001b[0m             \u001b[1;31m# Preserve original exception in case os.close raises.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;32mC:\\Anaconda\\lib\\subprocess.pyc\u001b[0m in \u001b[0;36m_execute_child\u001b[1;34m(self, args, executable, preexec_fn, close_fds, cwd, env, universal_newlines, startupinfo, creationflags, shell, to_close, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite)\u001b[0m\n\u001b[0;32m    956\u001b[0m                                          \u001b[0menv\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    957\u001b[0m                                          \u001b[0mcwd\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 958\u001b[1;33m                                          startupinfo)\n\u001b[0m\u001b[0;32m    959\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mpywintypes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    960\u001b[0m                 \u001b[1;31m# Translate pywintypes.error to WindowsError, which is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
        "\u001b[1;31mWindowsError\u001b[0m: [Error 193] %1 is not a valid Win32 application"
       ]
      }
     ],
     "prompt_number": 42
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# find the topics of a particular document\n",
      "model[dictionary.doc2bow(italians.tokens.iloc[0])] #.tolist()\n",
      "\n",
      "# print the most likely words of topics\n",
      "model.show_topics(num_topics=10, num_words=10, formatted=False)\n",
      "\n",
      "# create the document topic probability matrix\n",
      "model[corpus]\n",
      "\n",
      "# create a numpy array of the document topic probability matrix\n",
      "gensim.matutils.corpus2dense(model[corpus],100) \n",
      "\n",
      " \n",
      "# print the words and their proportions in a topic\n",
      "model.print_topic(81, topn=10) "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 10,
       "text": [
        "u'nan*gaj + nan*fanell + nan*anales + nan*inesatt + nan*i.t.=import + nan*dokton + nan*763-780 + nan*cannarozz + nan*brutus + nan*lots'"
       ]
      }
     ],
     "prompt_number": 10
    }
   ],
   "metadata": {}
  }
 ]
}